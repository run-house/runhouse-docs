{"parents": [], "prev": {"link": "../inference/", "title": "Inference: Stable Diffusion and FLAN-T5"}, "next": {"link": "../distributed/", "title": "Distributed: HF Accelerate"}, "title": "Training: Transformers", "meta": {}, "body": "<section id=\"training-transformers\">\n<h1>Training: Transformers<a class=\"headerlink\" href=\"#training-transformers\" title=\"Permalink to this heading\">\u00b6</a></h1>\n<p><a href=\"https://colab.research.google.com/github/run-house/runhouse/blob/stable/docs/notebooks/examples/training.ipynb\">\n<img height=\"20px\" width=\"117px\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a></p><p>This tutorial demonstrates how to use Runhouse to facilitate model\ntraining on <strong>your own GPU</strong>. With Runhouse, easily run your local code\nor training script on a remote cluster, and reproducibly set up your\nremote training environment.</p>\n<p>You can run this on your own cluster, or through a standard cloud\naccount (AWS, GCP, Azure, LambdaLabs). If you do not have any compute or\ncloud accounts set up, we recommend creating a\n<a class=\"reference external\" href=\"https://cloud.lambdalabs.com/\">LambdaLabs</a> account for the easiest\nsetup path.</p>\n<section id=\"table-of-contents\">\n<h2>Table of Contents<a class=\"headerlink\" href=\"#table-of-contents\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<ul class=\"simple\">\n<li><p>Hardware Setup</p></li>\n<li><p>Dataloading and Preprocessing</p></li>\n<li><p>Model Training</p></li>\n</ul>\n</section>\n<section id=\"install-runhouse\">\n<h2>Install Runhouse<a class=\"headerlink\" href=\"#install-runhouse\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span>!pip install runhouse\n</pre></div>\n</div>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span>import runhouse as rh\n</pre></div>\n</div>\n<div class=\"code-output highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">INFO</span> <span class=\"o\">|</span> <span class=\"mi\">2023</span><span class=\"o\">-</span><span class=\"mi\">06</span><span class=\"o\">-</span><span class=\"mi\">08</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">12</span><span class=\"p\">:</span><span class=\"mi\">34</span><span class=\"p\">,</span><span class=\"mi\">980</span> <span class=\"o\">|</span> <span class=\"n\">No</span> <span class=\"n\">auth</span> <span class=\"n\">token</span> <span class=\"n\">provided</span><span class=\"p\">,</span> <span class=\"n\">so</span> <span class=\"ow\">not</span> <span class=\"n\">using</span> <span class=\"n\">RNS</span> <span class=\"n\">API</span> <span class=\"n\">to</span> <span class=\"n\">save</span> <span class=\"ow\">and</span> <span class=\"n\">load</span> <span class=\"n\">configs</span>\n<span class=\"n\">INFO</span> <span class=\"o\">|</span> <span class=\"mi\">2023</span><span class=\"o\">-</span><span class=\"mi\">06</span><span class=\"o\">-</span><span class=\"mi\">08</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">12</span><span class=\"p\">:</span><span class=\"mi\">36</span><span class=\"p\">,</span><span class=\"mi\">499</span> <span class=\"o\">|</span> <span class=\"n\">NumExpr</span> <span class=\"n\">defaulting</span> <span class=\"n\">to</span> <span class=\"mi\">2</span> <span class=\"n\">threads</span><span class=\"o\">.</span>\n</pre></div>\n</div>\n</section>\n<section id=\"hardware-setup\">\n<h2>Hardware Setup<a class=\"headerlink\" href=\"#hardware-setup\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<p>If you\u2019re not already familiar with setting up a Runhouse cluster,\nplease first refer to <a class=\"reference external\" href=\"https://www.run.house/docs/tutorials/quick_start#cluster-setup\">Cluster\nSetup</a>\nfor a more introductory and in-depth walkthrough.</p>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span># Optional, to sync over any hardware credentials and configs from your Runhouse account\n!runhouse login --yes\n\n# alternatively, to set up credentials locally, run `!sky check` and follow the instructions for your cloud provider(s)\n# !sky check\n</pre></div>\n</div>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span># sample on-demand cluster, launched through Runhouse/SkyPilot\ngpu = rh.ondemand_cluster(name=&#39;rh-a10x&#39;, instance_type=&#39;g5.2xlarge&#39;, provider=&#39;aws&#39;).up_if_not()\n\n# or for your own dedicated cluster\n# gpu = rh.cluster(\n#            name=&quot;cpu-cluster&quot;,\n#            ips=[&#39;&lt;ip of the cluster&gt;&#39;],\n#            ssh_creds={&#39;ssh_user&#39;: &#39;&lt;user&gt;&#39;, &#39;ssh_private_key&#39;:&#39;&lt;path_to_key&gt;&#39;},\n#       )\n</pre></div>\n</div>\n<div class=\"code-output highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">INFO</span> <span class=\"o\">|</span> <span class=\"mi\">2023</span><span class=\"o\">-</span><span class=\"mi\">06</span><span class=\"o\">-</span><span class=\"mi\">08</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">30</span><span class=\"p\">:</span><span class=\"mi\">56</span><span class=\"p\">,</span><span class=\"mi\">926</span> <span class=\"o\">|</span> <span class=\"n\">Attempting</span> <span class=\"n\">to</span> <span class=\"n\">load</span> <span class=\"n\">config</span> <span class=\"k\">for</span> <span class=\"o\">/</span><span class=\"n\">carolineechen</span><span class=\"o\">/</span><span class=\"n\">rh</span><span class=\"o\">-</span><span class=\"n\">a10x</span> <span class=\"kn\">from</span> <span class=\"nn\">RNS.</span>\n</pre></div>\n</div>\n<div class=\"code-output highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">Output</span><span class=\"p\">()</span>\n</pre></div>\n</div>\n</section>\n<section id=\"dataloading-and-preprocessing\">\n<h2>Dataloading and Preprocessing<a class=\"headerlink\" href=\"#dataloading-and-preprocessing\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<p>Here, we briefly demonstrate data loading and preprocessing on our remote hardware.</p>\n<p>Steps:</p>\n<ul class=\"simple\">\n<li><p>take our preprocessing code, wrap it in a function called load_and_preprocess</p></li>\n<li><p>create a runhouse function, send it along w/ dependencies to the cluster, auto set up is handled</p></li>\n<li><p>call the function (which runs remotely on the cluster!)</p></li>\n</ul>\n<p>Note that all the code inside the function runs on our gpu cluster,\nwhich means there\u2019s no need to install anything locally either.</p>\n<p>For a more in-depth walkthrough of Runhouse\u2019s function and env APIs,\nplease refer to the <a class=\"reference external\" href=\"https://www.run.house/docs/tutorials/api/compute\">Compute API\nTutorial</a>.</p>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span>def load_and_preprocess():\n    from datasets import load_dataset\n\n    dataset = load_dataset(&quot;yelp_review_full&quot;)\n    dataset[&quot;train&quot;][100]\n\n    from transformers import AutoTokenizer\n    tokenizer = AutoTokenizer.from_pretrained(&quot;bert-base-cased&quot;)\n\n    def tokenize_function(examples):\n        return tokenizer(examples[&quot;text&quot;], padding=&quot;max_length&quot;, truncation=True)\n\n    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n    small_train_dataset = tokenized_datasets[&quot;train&quot;].shuffle(seed=42).select(range(1000))\n    small_eval_dataset = tokenized_datasets[&quot;test&quot;].shuffle(seed=42).select(range(1000))\n    return [small_train_dataset, small_eval_dataset]\n</pre></div>\n</div>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span>reqs = [&quot;transformers&quot;, &quot;datasets&quot;, &quot;torch&quot;]\n\nload_and_preprocess = rh.function(fn=load_and_preprocess).to(gpu, env=reqs)\n</pre></div>\n</div>\n<div class=\"code-output highlight-default notranslate\"><div class=\"highlight\"><pre><span></span>INFO | 2023-06-08 18:43:59,993 | Writing out function function to /content/load_and_preprocess_fn.py. Please make sure the function does not rely on any local variables, including imports (which should be moved inside the function body).\nINFO | 2023-06-08 18:44:00,000 | Setting up Function on cluster.\nINFO | 2023-06-08 18:44:00,478 | Connected (version 2.0, client OpenSSH_8.2p1)\nINFO | 2023-06-08 18:44:00,684 | Authentication (publickey) successful!\nINFO | 2023-06-08 18:44:07,003 | Installing packages on cluster rh-a10x: [&#39;transformers&#39;, &#39;datasets&#39;, &#39;torch&#39;, &#39;Package: content&#39;]\nINFO | 2023-06-08 18:46:10,042 | Function setup complete.\n</pre></div>\n</div>\n<p>Runhouse functions work so that you call them as you would with a local\nfunction (e.g.\u00a0<code class=\"docutils literal notranslate\"><span class=\"pre\">data</span> <span class=\"pre\">=</span> <span class=\"pre\">load_and_preprocess()</span></code>) \u2013 the code runs\nremotely and returns the object locally.</p>\n<p>However, in this case, as we are running training on the same cluster\nand it\u2019s not useful to have the dataset sent back to local, we can\nsimply call <code class=\"docutils literal notranslate\"><span class=\"pre\">.remote()</span></code> on the function to have it run async,\nreturning an object reference to our dataset rather than the actual\ndata. This dataset ref can be passed into later functions as if they\nwere the actual object.</p>\n<p>If you\u2019d like to save down your data to file storage (e.g.\u00a0<code class=\"docutils literal notranslate\"><span class=\"pre\">s3</span></code>,\n<code class=\"docutils literal notranslate\"><span class=\"pre\">gcs</span></code>), Runhouse also has API support for that. Please refer to our\nData API Tutorial for more information on that.</p>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span>datasets_ref = load_and_preprocess.remote()\n</pre></div>\n</div>\n<pre class=\"code-output literal-block\">INFO | 2023-06-08 18:52:55,092 | Running load_and_preprocess via HTTP\nINFO | 2023-06-08 18:52:55,191 | Time to call remote function: 0.1 seconds\nINFO | 2023-06-08 18:52:55,193 | Submitted remote call to cluster. Result or logs can be retrieved\n with run_key &quot;load_and_preprocess_20230608_185255&quot;, e.g.\n<cite>rh.cluster(name=&quot;/carolineechen/rh-a10x&quot;).get(&quot;load_and_preprocess_20230608_185255&quot;, stream_logs=True)</cite> in python\n<cite>runhouse logs &quot;rh-a10x&quot; load_and_preprocess_20230608_185255</cite> from the command line.\n or cancelled with\n<cite>rh.cluster(name=&quot;/carolineechen/rh-a10x&quot;).cancel(&quot;load_and_preprocess_20230608_185255&quot;)</cite> in python or\n<cite>runhouse cancel &quot;rh-a10x&quot; load_and_preprocess_20230608_185255</cite> from the command line.</pre>\n</section>\n<section id=\"training\">\n<h2>Training<a class=\"headerlink\" href=\"#training\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<p>Now that we have the dataset ready, it\u2019s time to train!</p>\n<p>In a similar flow as above: - take our training code, wrap it in a\n<code class=\"docutils literal notranslate\"><span class=\"pre\">train</span></code> function - specify the function and relevant dependencies to\nbe synced and installed on the remote cluster - call the function from\nlocal, passing in your dataset reference, and watch it train remotely</p>\n<p>Later on, we also demonstrate how you can run training from an existing\nscript.</p>\n<section id=\"training-from-locally-defined-functions\">\n<h3>Training from locally defined functions<a class=\"headerlink\" href=\"#training-from-locally-defined-functions\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span>def train(hf_datasets):\n    [small_train_dataset, small_eval_dataset] = hf_datasets\n\n    from transformers import AutoModelForSequenceClassification\n\n    model = AutoModelForSequenceClassification.from_pretrained(&quot;bert-base-cased&quot;, num_labels=5)\n\n    import numpy as np\n    import evaluate\n\n    metric = evaluate.load(&quot;accuracy&quot;)  # Requires scikit-learn\n\n    def compute_metrics(eval_pred):\n        logits, labels = eval_pred\n        predictions = np.argmax(logits, axis=-1)\n        return metric.compute(predictions=predictions, references=labels)\n\n    from transformers import TrainingArguments, Trainer\n\n    training_args = TrainingArguments(output_dir=&quot;test_trainer&quot;, evaluation_strategy=&quot;epoch&quot;)\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=small_train_dataset,\n        eval_dataset=small_eval_dataset,\n        compute_metrics=compute_metrics,\n    )\n\n    trainer.train()\n</pre></div>\n</div>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span>extra_reqs = [&#39;evaluate&#39;, &#39;scikit-learn&#39;, &#39;accelerate&#39;]\n\ntrain = rh.function(fn=train).to(gpu, env=extra_reqs)\n</pre></div>\n</div>\n<div class=\"code-output highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">INFO</span> <span class=\"o\">|</span> <span class=\"mi\">2023</span><span class=\"o\">-</span><span class=\"mi\">06</span><span class=\"o\">-</span><span class=\"mi\">08</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">53</span><span class=\"p\">:</span><span class=\"mi\">03</span><span class=\"p\">,</span><span class=\"mi\">726</span> <span class=\"o\">|</span> <span class=\"n\">Writing</span> <span class=\"n\">out</span> <span class=\"n\">function</span> <span class=\"n\">function</span> <span class=\"n\">to</span> <span class=\"o\">/</span><span class=\"n\">content</span><span class=\"o\">/</span><span class=\"n\">train_fn</span><span class=\"o\">.</span><span class=\"n\">py</span><span class=\"o\">.</span> <span class=\"n\">Please</span> <span class=\"n\">make</span> <span class=\"n\">sure</span> <span class=\"n\">the</span> <span class=\"n\">function</span> <span class=\"n\">does</span> <span class=\"ow\">not</span> <span class=\"n\">rely</span> <span class=\"n\">on</span> <span class=\"nb\">any</span> <span class=\"n\">local</span> <span class=\"n\">variables</span><span class=\"p\">,</span> <span class=\"n\">including</span> <span class=\"n\">imports</span> <span class=\"p\">(</span><span class=\"n\">which</span> <span class=\"n\">should</span> <span class=\"n\">be</span> <span class=\"n\">moved</span> <span class=\"n\">inside</span> <span class=\"n\">the</span> <span class=\"n\">function</span> <span class=\"n\">body</span><span class=\"p\">)</span><span class=\"o\">.</span>\n<span class=\"n\">INFO</span> <span class=\"o\">|</span> <span class=\"mi\">2023</span><span class=\"o\">-</span><span class=\"mi\">06</span><span class=\"o\">-</span><span class=\"mi\">08</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">53</span><span class=\"p\">:</span><span class=\"mi\">03</span><span class=\"p\">,</span><span class=\"mi\">730</span> <span class=\"o\">|</span> <span class=\"n\">Setting</span> <span class=\"n\">up</span> <span class=\"n\">Function</span> <span class=\"n\">on</span> <span class=\"n\">cluster</span><span class=\"o\">.</span>\n<span class=\"n\">INFO</span> <span class=\"o\">|</span> <span class=\"mi\">2023</span><span class=\"o\">-</span><span class=\"mi\">06</span><span class=\"o\">-</span><span class=\"mi\">08</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">53</span><span class=\"p\">:</span><span class=\"mi\">05</span><span class=\"p\">,</span><span class=\"mi\">568</span> <span class=\"o\">|</span> <span class=\"n\">Installing</span> <span class=\"n\">packages</span> <span class=\"n\">on</span> <span class=\"n\">cluster</span> <span class=\"n\">rh</span><span class=\"o\">-</span><span class=\"n\">a10x</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">&#39;evaluate&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;scikit-learn&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;accelerate&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Package: content&#39;</span><span class=\"p\">]</span>\n<span class=\"n\">INFO</span> <span class=\"o\">|</span> <span class=\"mi\">2023</span><span class=\"o\">-</span><span class=\"mi\">06</span><span class=\"o\">-</span><span class=\"mi\">08</span> <span class=\"mi\">18</span><span class=\"p\">:</span><span class=\"mi\">53</span><span class=\"p\">:</span><span class=\"mi\">17</span><span class=\"p\">,</span><span class=\"mi\">394</span> <span class=\"o\">|</span> <span class=\"n\">Function</span> <span class=\"n\">setup</span> <span class=\"n\">complete</span><span class=\"o\">.</span>\n</pre></div>\n</div>\n<p>To run the function, call it as you would any Python function. Pass in the dataset reference, and optionally add <cite>stream_logs=True</cite> to see the logs locally.</p>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span>train(datasets_ref, stream_logs=True)\n</pre></div>\n</div>\n<pre class=\"code-output literal-block\">INFO | 2023-06-08 18:53:21,114 | Running train via HTTP\nINFO | 2023-06-08 18:56:10,362 | Time to call remote function: 169.25 seconds\nINFO | 2023-06-08 18:56:10,365 | Submitted remote call to cluster. Result or logs can be retrieved\n with run_key &quot;train_20230608_185610&quot;, e.g.\n<cite>rh.cluster(name=&quot;/carolineechen/rh-a10x&quot;).get(&quot;train_20230608_185610&quot;, stream_logs=True)</cite> in python\n<cite>runhouse logs &quot;rh-a10x&quot; train_20230608_185610</cite> from the command line.\n or cancelled with\n<cite>rh.cluster(name=&quot;/carolineechen/rh-a10x&quot;).cancel(&quot;train_20230608_185610&quot;)</cite> in python or\n<cite>runhouse cancel &quot;rh-a10x&quot; train_20230608_185610</cite> from the command line.\n:job_id:01000000\n:task_name:get_fn_from_pointers\n:job_id:01000000\nINFO | 2023-06-08 18:56:11,007 | Loaded Runhouse config from /home/ubuntu/.rh/config.yaml\n:task_name:get_fn_from_pointers\nINFO | 2023-06-08 18:56:11,821 | Writing logs on cluster to /home/ubuntu/.rh/logs/train_20230608_185610\nINFO | 2023-06-08 18:56:11,821 | Appending /home/ubuntu/content to sys.path\nINFO | 2023-06-08 18:56:11,821 | Importing module train_fn\n\nDownloading model.safetensors:   0%|          | 0.00/436M [00:00&lt;?, ?B/s]\nDownloading model.safetensors:  12%|\u2588\u258f        | 52.4M/436M [00:00&lt;00:00, 468MB/s]\nDownloading model.safetensors:  24%|\u2588\u2588\u258d       | 105M/436M [00:00&lt;00:00, 490MB/s]\nDownloading model.safetensors:  36%|\u2588\u2588\u2588\u258c      | 157M/436M [00:00&lt;00:00, 447MB/s]\nDownloading model.safetensors:  48%|\u2588\u2588\u2588\u2588\u258a     | 210M/436M [00:00&lt;00:00, 446MB/s]\nDownloading model.safetensors:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 262M/436M [00:00&lt;00:00, 448MB/s]\nDownloading model.safetensors:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 315M/436M [00:00&lt;00:00, 456MB/s]\nDownloading model.safetensors:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 367M/436M [00:00&lt;00:00, 472MB/s]\nDownloading model.safetensors:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 419M/436M [00:00&lt;00:00, 480MB/s]\nDownloading model.safetensors: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 436M/436M [00:00&lt;00:00, 467MB/s]\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\nDownloading builder script:   0%|          | 0.00/4.20k [00:00&lt;?, ?B/s]\nDownloading builder script: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.20k/4.20k [00:00&lt;00:00, 7.13MB/s]\n\n  0%|          | 0/375 [00:00&lt;?, ?it/s]\n  0%|          | 1/375 [01:11&lt;7:28:39, 71.98s/it]\n  1%|          | 2/375 [01:12&lt;3:05:04, 29.77s/it]\n  1%|          | 3/375 [01:12&lt;1:40:56, 16.28s/it]\n  1%|          | 4/375 [01:12&lt;1:01:29,  9.94s/it]\n  1%|\u258f         | 5/375 [01:12&lt;39:42,  6.44s/it]\n  2%|\u258f         | 6/375 [01:13&lt;26:37,  4.33s/it]\n  2%|\u258f         | 7/375 [01:13&lt;18:19,  2.99s/it]\n  2%|\u258f         | 8/375 [01:13&lt;12:54,  2.11s/it]\n  2%|\u258f         | 9/375 [01:13&lt;09:16,  1.52s/it]\n  3%|\u258e         | 10/375 [01:14&lt;06:49,  1.12s/it]\n[... truncated output ...]\n 31%|\u2588\u2588\u2588       | 115/375 [01:37&lt;00:59,  4.38it/s]\n 31%|\u2588\u2588\u2588       | 116/375 [01:38&lt;00:59,  4.39it/s]\n 31%|\u2588\u2588\u2588       | 117/375 [01:38&lt;00:58,  4.38it/s]\n 31%|\u2588\u2588\u2588\u258f      | 118/375 [01:38&lt;00:58,  4.38it/s]\n 32%|\u2588\u2588\u2588\u258f      | 119/375 [01:38&lt;00:58,  4.38it/s]\n 32%|\u2588\u2588\u2588\u258f      | 120/375 [01:39&lt;00:58,  4.38it/s]\n 32%|\u2588\u2588\u2588\u258f      | 121/375 [01:39&lt;00:57,  4.38it/s]\n 33%|\u2588\u2588\u2588\u258e      | 122/375 [01:39&lt;00:57,  4.38it/s]\n 33%|\u2588\u2588\u2588\u258e      | 123/375 [01:39&lt;00:57,  4.38it/s]\n 33%|\u2588\u2588\u2588\u258e      | 124/375 [01:40&lt;00:57,  4.38it/s]\n 33%|\u2588\u2588\u2588\u258e      | 125/375 [01:40&lt;00:57,  4.38it/s]\n\n  0%|          | 0/125 [00:00&lt;?, ?it/s]\u001b[A\n\n  2%|\u258f         | 3/125 [00:00&lt;00:06, 19.31it/s]\u001b[A\n\n  4%|\u258d         | 5/125 [00:00&lt;00:07, 15.52it/s]\u001b[A\n\n  6%|\u258c         | 7/125 [00:00&lt;00:08, 14.32it/s]\u001b[A\n\n[... truncated output ...]\n\n 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 113/125 [00:08&lt;00:00, 12.87it/s]\u001b[A\n\n 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 115/125 [00:08&lt;00:00, 12.87it/s]\u001b[A\n\n 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 117/125 [00:09&lt;00:00, 12.87it/s]\u001b[A\n\n 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 119/125 [00:09&lt;00:00, 12.86it/s]\u001b[A\n\n 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 121/125 [00:09&lt;00:00, 12.86it/s]\u001b[A\n\n 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 123/125 [00:09&lt;00:00, 12.86it/s]\u001b[A\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [00:09&lt;00:00, 12.87it/s]\u001b[A\n\n\u001b[A\n 33%|\u2588\u2588\u2588\u258e      | 125/375 [01:50&lt;00:57,  4.38it/s]\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [00:09&lt;00:00, 12.87it/s]\u001b[A\n\n                                                 \u001b[A\n\n 34%|\u2588\u2588\u2588\u258e      | 126/375 [01:50&lt;13:03,  3.15s/it]{'eval_loss': 1.1413816213607788, 'eval_accuracy': 0.518, 'eval_runtime': 9.7297, 'eval_samples_per_second': 102.778, 'eval_steps_per_second': 12.847, 'epoch': 1.0}\n\n 34%|\u2588\u2588\u2588\u258d      | 127/375 [01:50&lt;09:23,  2.27s/it]\n 34%|\u2588\u2588\u2588\u258d      | 128/375 [01:50&lt;06:49,  1.66s/it]\n 34%|\u2588\u2588\u2588\u258d      | 129/375 [01:50&lt;05:02,  1.23s/it]\n 35%|\u2588\u2588\u2588\u258d      | 130/375 [01:51&lt;03:47,  1.08it/s]\n 35%|\u2588\u2588\u2588\u258d      | 131/375 [01:51&lt;02:55,  1.39it/s]\n 35%|\u2588\u2588\u2588\u258c      | 132/375 [01:51&lt;02:18,  1.75it/s]\n 35%|\u2588\u2588\u2588\u258c      | 133/375 [01:51&lt;01:53,  2.13it/s]\n 36%|\u2588\u2588\u2588\u258c      | 134/375 [01:52&lt;01:35,  2.52it/s]\n[... truncated output ...]\n 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 240/375 [02:16&lt;00:30,  4.38it/s]\n 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 241/375 [02:16&lt;00:30,  4.38it/s]\n 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 242/375 [02:16&lt;00:30,  4.37it/s]\n 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 243/375 [02:16&lt;00:30,  4.38it/s]\n 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 244/375 [02:17&lt;00:29,  4.38it/s]\n 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 245/375 [02:17&lt;00:29,  4.37it/s]\n 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 246/375 [02:17&lt;00:29,  4.38it/s]\n 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 247/375 [02:17&lt;00:29,  4.38it/s]\n 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 248/375 [02:18&lt;00:29,  4.37it/s]\n 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 249/375 [02:18&lt;00:28,  4.38it/s]\n 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 250/375 [02:18&lt;00:28,  4.38it/s]\n\n  0%|          | 0/125 [00:00&lt;?, ?it/s]\u001b[A\n\n  2%|\u258f         | 3/125 [00:00&lt;00:06, 19.24it/s]\u001b[A\n\n  4%|\u258d         | 5/125 [00:00&lt;00:07, 15.45it/s]\u001b[A\n\n  6%|\u258c         | 7/125 [00:00&lt;00:08, 14.28it/s]\u001b[A\n\n  7%|\u258b         | 9/125 [00:00&lt;00:08, 13.72it/s]\u001b[A\n\n  9%|\u2589         | 11/125 [00:00&lt;00:08, 13.39it/s]\u001b[A\n\n[... truncated output ...]\n\n 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 115/125 [00:08&lt;00:00, 12.83it/s]\u001b[A\n\n 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 117/125 [00:09&lt;00:00, 12.84it/s]\u001b[A\n\n 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 119/125 [00:09&lt;00:00, 12.83it/s]\u001b[A\n\n 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 121/125 [00:09&lt;00:00, 12.82it/s]\u001b[A\n\n 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 123/125 [00:09&lt;00:00, 12.81it/s]\u001b[A\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [00:09&lt;00:00, 12.83it/s]\u001b[A\n\n\n\n\u001b[A\n 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 250/375 [02:28&lt;00:28,  4.38it/s]\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [00:09&lt;00:00, 12.83it/s]\u001b[A\n\n                                                 \u001b[A{'eval_loss': 1.0151797533035278, 'eval_accuracy': 0.576, 'eval_runtime': 9.7523, 'eval_samples_per_second': 102.539, 'eval_steps_per_second': 12.817, 'epoch': 2.0}\n\n 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 251/375 [02:28&lt;06:34,  3.18s/it]\n 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 252/375 [02:28&lt;04:42,  2.29s/it]\n 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 253/375 [02:29&lt;03:24,  1.67s/it]\n 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 254/375 [02:29&lt;02:30,  1.24s/it]\n 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 255/375 [02:29&lt;01:52,  1.07it/s]\n[... truncated output ...]\n 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 371/375 [02:56&lt;00:00,  4.37it/s]\n 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 372/375 [02:56&lt;00:00,  4.37it/s]\n 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 373/375 [02:56&lt;00:00,  4.37it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 374/375 [02:56&lt;00:00,  4.37it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 375/375 [02:56&lt;00:00,  4.38it/s]\n\n  0%|          | 0/125 [00:00&lt;?, ?it/s]\u001b[A\n\n  2%|\u258f         | 3/125 [00:00&lt;00:06, 19.19it/s]\u001b[A\n\n  4%|\u258d         | 5/125 [00:00&lt;00:07, 15.41it/s]\u001b[A\n\n  6%|\u258c         | 7/125 [00:00&lt;00:08, 14.22it/s]\u001b[A\n\n  7%|\u258b         | 9/125 [00:00&lt;00:08, 13.69it/s]\u001b[A\n\n  9%|\u2589         | 11/125 [00:00&lt;00:08, 13.37it/s]\u001b[A\n\n 10%|\u2588         | 13/125 [00:00&lt;00:08, 13.18it/s]\u001b[A\n\n 12%|\u2588\u258f        | 15/125 [00:01&lt;00:08, 13.06it/s]\u001b[A\n\n[... truncated output ...]\n\n 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 111/125 [00:08&lt;00:01, 12.82it/s]\u001b[A\n\n 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 113/125 [00:08&lt;00:00, 12.83it/s]\u001b[A\n\n 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 115/125 [00:08&lt;00:00, 12.82it/s]\u001b[A\n\n 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 117/125 [00:09&lt;00:00, 12.82it/s]\u001b[A\n\n 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 119/125 [00:09&lt;00:00, 12.83it/s]\u001b[A\n\n 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 121/125 [00:09&lt;00:00, 12.83it/s]\u001b[A\n\n 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 123/125 [00:09&lt;00:00, 12.83it/s]\u001b[A\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [00:09&lt;00:00, 12.83it/s]\u001b[A\n\n\n\n\u001b[A\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 375/375 [03:06&lt;00:00,  4.38it/s]\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 125/125 [00:09&lt;00:00, 12.83it/s]\u001b[A\n\n                                                 \u001b[A\n\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 375/375 [03:06&lt;00:00,  4.38it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 375/375 [03:06&lt;00:00,  2.01it/s]\n{'eval_loss': 1.0775768756866455, 'eval_accuracy': 0.568, 'eval_runtime': 9.7574, 'eval_samples_per_second': 102.486, 'eval_steps_per_second': 12.811, 'epoch': 3.0}\n{'train_runtime': 186.7323, 'train_samples_per_second': 16.066, 'train_steps_per_second': 2.008, 'train_loss': 0.98061328125, 'epoch': 3.0}</pre>\n</section>\n<section id=\"training-from-existing-script\">\n<h3>Training from existing script<a class=\"headerlink\" href=\"#training-from-existing-script\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<p>Runhouse also makes it easy to run scripts and commands on your remote\ncluster, so if you have an existing training script, you can easily\ndirectly run that on your remote compute as well.</p>\n<ul class=\"simple\">\n<li><p>Sync over your working directory with the training script to the\ncluster</p></li>\n<li><p>Set up environment and package installations on the cluster</p></li>\n<li><p>Run the script with a simple command</p></li>\n</ul>\n<p>To sync over the working directory, you can create a Runhouse folder\nresource and send it over to the cluster.</p>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span>rh.folder(path=&quot;local_folder_path&quot;, dest_path=&quot;remote_folder_path&quot;).to(gpu)\n</pre></div>\n</div>\n<p>Alternatively, if the script lives inside a GitHub repo, you could also\ndirectly clone and install the GitHub repo remotely with the GitPackage\nAPI.</p>\n<p>In this case, let\u2019s say we\u2019re trying to access and run\n<a class=\"reference external\" href=\"https://github.com/huggingface/accelerate/blob/v0.15.0/examples/nlp_example.py\">examples/nlp_example.py</a>\nfrom the <a class=\"reference external\" href=\"https://github.com/huggingface/accelerate\">accelerate GitHub\nrepo</a>.</p>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span>git_package = rh.git_package(git_url=&#39;https://github.com/huggingface/accelerate.git&#39;,\n                            install_method=&#39;pip&#39;,\n                            revision=&#39;v0.18.0&#39;)\ngpu.install_packages([git_package])\n</pre></div>\n</div>\n<div class=\"code-output highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">INFO</span> <span class=\"o\">|</span> <span class=\"mi\">2023</span><span class=\"o\">-</span><span class=\"mi\">06</span><span class=\"o\">-</span><span class=\"mi\">08</span> <span class=\"mi\">19</span><span class=\"p\">:</span><span class=\"mi\">57</span><span class=\"p\">:</span><span class=\"mi\">11</span><span class=\"p\">,</span><span class=\"mi\">991</span> <span class=\"o\">|</span> <span class=\"n\">Installing</span> <span class=\"n\">packages</span> <span class=\"n\">on</span> <span class=\"n\">cluster</span> <span class=\"n\">rh</span><span class=\"o\">-</span><span class=\"n\">a10x</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">&#39;GitPackage: https://github.com/huggingface/accelerate.git@v0.18.0&#39;</span><span class=\"p\">]</span>\n</pre></div>\n</div>\n<p>Additionally install any other necessary requirements to run the script.</p>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span>reqs = [&#39;evaluate&#39;, &#39;transformers&#39;, &#39;datasets==2.3.2&#39;, &#39;scipy&#39;, &#39;scikit-learn&#39;, &#39;tqdm&#39;, &#39;tensorboard&#39;, &#39;torch==1.12.0&#39;]\n\nenv = rh.env(reqs=reqs)\nenv.to(gpu)\n\n# or\n# gpu.install_packages(reqs)\n</pre></div>\n</div>\n<p>Now that we have the script and dependencies on the cluster, we can run\nthe script using <code class=\"docutils literal notranslate\"><span class=\"pre\">gpu.run([command])</span></code></p>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span>gpu.run([&#39;python accelerate/examples/nlp_example.py&#39;])\n</pre></div>\n</div>\n</section>\n</section>\n<section id=\"terminate-cluster\">\n<h2>Terminate Cluster<a class=\"headerlink\" href=\"#terminate-cluster\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<p>To terminate the cluster after you\u2019re done using it, you can either use\nthe <code class=\"docutils literal notranslate\"><span class=\"pre\">sky</span> <span class=\"pre\">down</span> <span class=\"pre\">cluster-name</span></code> CLI command or <code class=\"docutils literal notranslate\"><span class=\"pre\">cluster_var.down()</span></code>\nPython API.</p>\n<p>If you set up autostop for the cluster or in your configs (default to 30\nmin), the cluster will automatically terminate after that period of\ninactivity.</p>\n<div class=\"highlight-ipython3 notranslate\"><div class=\"highlight\"><pre><span></span># cli\n!sky down rh-a10x\n\n# python\n# gpu.down()\n</pre></div>\n</div>\n<div class=\"code-output highlight-default notranslate\"><div class=\"highlight\"><pre><span></span>Terminating 1 cluster: rh-a10x. Proceed? [Y/n]: y\n\u001b[2K\u001b[1;36mTerminating 1 cluster\u001b[0m \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n\u001b[2K\u001b[1;36mTerminating 1 cluster\u001b[0m \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n\u001b[1A\u001b[2K\u001b[32mTerminating cluster rh-a10x...done.\u001b[0m\n\u001b[2K\u001b[1;36mTerminating 1 cluster\u001b[0m \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[0m\n</pre></div>\n</div>\n</section>\n</section>\n\n    <script type=\"text/x-thebe-config\">\n    {\n        requestKernel: true,\n        binderOptions: {\n            repo: \"binder-examples/jupyter-stacks-datascience\",\n            ref: \"master\",\n        },\n        codeMirrorConfig: {\n            theme: \"abcdef\",\n            mode: \"python\"\n        },\n        kernelOptions: {\n            name: \"python3\",\n            path: \"./tutorials/examples\"\n        },\n        predefinedOutput: true\n    }\n    </script>\n    <script>kernelName = 'python3'</script>", "metatags": "<meta name=\"generator\" content=\"Docutils 0.19: https://docutils.sourceforge.io/\" />\n", "rellinks": [["genindex", "General Index", "I", "index"], ["py-modindex", "Python Module Index", "", "modules"], ["tutorials/examples/distributed", "Distributed: HF Accelerate", "N", "next"], ["tutorials/examples/inference", "Inference: Stable Diffusion and FLAN-T5", "P", "previous"]], "sourcename": "tutorials/examples/training.rst.txt", "toc": "<ul>\n<li><a class=\"reference internal\" href=\"#\">Training: Transformers</a><ul>\n<li><a class=\"reference internal\" href=\"#table-of-contents\">Table of Contents</a></li>\n<li><a class=\"reference internal\" href=\"#install-runhouse\">Install Runhouse</a></li>\n<li><a class=\"reference internal\" href=\"#hardware-setup\">Hardware Setup</a></li>\n<li><a class=\"reference internal\" href=\"#dataloading-and-preprocessing\">Dataloading and Preprocessing</a></li>\n<li><a class=\"reference internal\" href=\"#training\">Training</a><ul>\n<li><a class=\"reference internal\" href=\"#training-from-locally-defined-functions\">Training from locally defined functions</a></li>\n<li><a class=\"reference internal\" href=\"#training-from-existing-script\">Training from existing script</a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#terminate-cluster\">Terminate Cluster</a></li>\n</ul>\n</li>\n</ul>\n", "display_toc": true, "page_source_suffix": ".rst", "globaltoc": "<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Getting Started</span></p>\n<ul>\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"tutorials/quick_start/\">Quick Start Guide</a></li>\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"architecture/\">Architecture Overview</a></li>\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"api_tutorials/\">API Tutorials</a><ul>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"tutorials/api/compute/\">Compute: Clusters, Functions, Packages, &amp; Envs</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"tutorials/api/data/\">Data: Folders, Tables, &amp; Blobs</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"tutorials/api/secrets/\">Secrets Management</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"tutorials/api/resources/\">Resource Management</a></li>\n</ul>\n</li>\n</ul>\n<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">API Reference</span></p>\n<ul>\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"api/python/\">Python API</a><ul>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"api/python/resource/\">Resource</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"api/python/function/\">Function</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"api/python/cluster/\">Cluster</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"api/python/env/\">Env</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"api/python/package/\">Package</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"api/python/module/\">Module</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"api/python/folder/\">Folder</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"api/python/table/\">Table</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"api/python/blob/\">Blob</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"api/python/file/\">File</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"api/python/secrets/\">Secrets</a></li>\n<li class=\"toctree-l2\"><a class=\"reference internal\" href=\"api/python/login/\">Login/Logout</a></li>\n</ul>\n</li>\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"api/cli/\">Command Line Interface</a></li>\n</ul>\n<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Usage Examples</span></p>\n<ul>\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"tutorials/examples/inference/\">Inference: Stable Diffusion and FLAN-T5</a></li>\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"tutorials/examples/training/\">Training: Transformers</a></li>\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"tutorials/examples/distributed/\">Distributed: HF Accelerate</a></li>\n<li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://github.com/run-house/funhouse/tree/main/bert_pipeline\">Pipelining: BERT</a></li>\n</ul>\n<p class=\"caption\" role=\"heading\"><span class=\"caption-text\">Additional Resources</span></p>\n<ul>\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"debugging_logging/\">Debugging and Logging</a></li>\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"troubleshooting/\">Manual Setup and Troubleshooting</a></li>\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"security_and_authentication/\">Security and Authentication</a></li>\n<li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://github.com/run-house/runhouse\">Source Code</a></li>\n<li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://api.run.house/docs\">REST API Guide</a></li>\n<li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://www.run.house/dashboard\">Runhouse Den Dashboard</a></li>\n<li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://github.com/run-house/funhouse\">Funhouse</a></li>\n</ul>\n", "current_page_name": "tutorials/examples/training", "sidebars": ["about.html", "navigation.html", "relations.html", "searchbox.html", "donate.html"], "customsidebar": null, "alabaster_version": "0.7.15", "alabaster_version_info": [0, 7, 15]}