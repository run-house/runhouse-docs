{"parents": [], "prev": {"link": "../clusters/", "title": "Clusters"}, "next": {"link": "../notebooks/", "title": "Notebooks"}, "title": "Functions", "meta": {}, "body": "<section id=\"functions\">\n<h1>Functions<a class=\"headerlink\" href=\"#functions\" title=\"Permalink to this heading\">\u00b6</a></h1>\n<p>Runhouse allows you to function code a cluster, but still interact with it as a native runnable <a class=\"reference internal\" href=\"../../rh_primitives/function/#id1\"><span class=\"std std-ref\">Function</span></a> object\n(see <a class=\"reference external\" href=\"https://github.com/run-house/tutorials/tree/main/t01_Stable_Diffusion/\">tutorial 01</a>).\nWhen you do this, the following steps occur:</p>\n<ol class=\"arabic simple\">\n<li><p>We check if the cluster is up, and bring up the cluster if not (only possible for OnDemandClusters)</p></li>\n<li><p>We check that the cluster\u2019s gRPC server has started to handle requests to do things like install packages, run modules, get previously executed results, etc. If it hasn\u2019t, we install Runhouse on the cluster and start the gRPC server. The gRPC server initializes Ray.</p></li>\n<li><p>We collect the dependencies from the <code class=\"code docutils literal notranslate\"><span class=\"pre\">reqs</span></code> parameter and install them on the cluster via <code class=\"code docutils literal notranslate\"><span class=\"pre\">cluster.install_packages()</span></code>. By default, we\u2019ll sync over the working git repo and install its <code class=\"code docutils literal notranslate\"><span class=\"pre\">requirements.txt</span></code> if it has one.</p></li>\n</ol>\n<p>When you run your function module, we send a gRPC request to the cluster with the module name and function entrypoint to run.\nThe gRPC server adds the module to its python path, imports the module, grabs the function entrypoint, runs it,\nand returns your results.</p>\n<p>You can stream in logs from the cluster as your module runs by passing <code class=\"code docutils literal notranslate\"><span class=\"pre\">stream_logs=True</span></code> into your call line:</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">images</span> <span class=\"o\">=</span> <span class=\"n\">generate_gpu</span><span class=\"p\">(</span><span class=\"s1\">&#39;A dog.&#39;</span><span class=\"p\">,</span> <span class=\"n\">num_images</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">steps</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">,</span> <span class=\"n\">stream_logs</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p>We plan to support additional form factors for modules beyond \u201cremote Python function\u201d shortly, including HTTP endpoints, custom ASGIs, and more.</p>\n<section id=\"advanced-function-usage\">\n<h2>Advanced Function Usage<a class=\"headerlink\" href=\"#advanced-function-usage\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<p>There are a number of ways to call a Function beyond just <code class=\"code docutils literal notranslate\"><span class=\"pre\">__call__</span></code>.</p>\n<p><code class=\"code docutils literal notranslate\"><span class=\"pre\">.remote</span></code> will call the function async (using Ray) and return a reference (<a class=\"reference external\" href=\"https://docs.ray.io/en/latest/ray-core/objects.html\">Ray ObjectRef</a>)\nto the object on the cluster. You can pass the ref into another function and it will be automatically\ndereferenced once on the cluster. This is a convenient way to avoid passing large objects back and forth to your\nlaptop, or to run longer execution in notebooks without locking up the kernel.</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">images_ref</span> <span class=\"o\">=</span> <span class=\"n\">generate_gpu</span><span class=\"o\">.</span><span class=\"n\">remote</span><span class=\"p\">(</span><span class=\"s1\">&#39;A dog.&#39;</span><span class=\"p\">,</span> <span class=\"n\">num_images</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">steps</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">)</span>\n<span class=\"n\">images</span> <span class=\"o\">=</span> <span class=\"n\">rh</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">images_ref</span><span class=\"p\">)</span>\n<span class=\"c1\"># or</span>\n<span class=\"n\">my_other_function</span><span class=\"p\">(</span><span class=\"n\">images_ref</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><code class=\"code docutils literal notranslate\"><span class=\"pre\">.enqueue</span></code> will queue up your function call on the cluster to make sure it doesn\u2019t run simultaneously with other\ncalls, but will wait until the execution completes.</p>\n<p><code class=\"code docutils literal notranslate\"><span class=\"pre\">.map</span></code> and <code class=\"code docutils literal notranslate\"><span class=\"pre\">.starmap</span></code> are easy way to parallelize your function (again using Ray on the cluster).</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">generate_gpu</span><span class=\"o\">.</span><span class=\"n\">map</span><span class=\"p\">([</span><span class=\"s1\">&#39;A dog.&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;A cat.&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;A biscuit.&#39;</span><span class=\"p\">],</span> <span class=\"n\">num_images</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span><span class=\"o\">*</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">steps</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">50</span><span class=\"p\">]</span><span class=\"o\">*</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p>will run the function on each of the three prompts, and return a list of the results.\nNote that the num_images and steps arguments are broadcasted to each prompt, so the first prompt will get 1 image.</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">generate_gpu</span><span class=\"o\">.</span><span class=\"n\">starmap</span><span class=\"p\">([(</span><span class=\"s1\">&#39;A dog.&#39;</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">&#39;A cat.&#39;</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">&#39;A biscuit.&#39;</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)],</span> <span class=\"n\">steps</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p>is the same as map as above, but we can pass the arguments as a list of tuples, and the steps argument as a single value, since it\u2019s the same for all three prompts.</p>\n</section>\n</section>\n\n    <script type=\"text/x-thebe-config\">\n    {\n        requestKernel: true,\n        binderOptions: {\n            repo: \"binder-examples/jupyter-stacks-datascience\",\n            ref: \"master\",\n        },\n        codeMirrorConfig: {\n            theme: \"abcdef\",\n            mode: \"python\"\n        },\n        kernelOptions: {\n            kernelName: \"python3\",\n            path: \"./overview\"\n        },\n        predefinedOutput: true\n    }\n    </script>\n    <script>kernelName = 'python3'</script>", "metatags": "<meta name=\"generator\" content=\"Docutils 0.18.1: http://docutils.sourceforge.net/\" />\n", "rellinks": [["genindex", "General Index", "I", "index"], ["overview/notebooks", "Notebooks", "N", "next"], ["overview/clusters", "Clusters", "P", "previous"]], "sourcename": "overview/functions.rst.txt", "toc": "<ul>\n<li><a class=\"reference internal\" href=\"#\">Functions</a><ul>\n<li><a class=\"reference internal\" href=\"#advanced-function-usage\">Advanced Function Usage</a></li>\n</ul>\n</li>\n</ul>\n", "display_toc": true, "page_source_suffix": ".rst", "current_page_name": "overview/functions", "sidebars": ["sidebar-logo.html", "search-field.html", "sbt-sidebar-nav.html", "sbt-sidebar-footer.html"], "customsidebar": null, "favicon_url": null, "logo_url": null, "alabaster_version": "0.7.12", "pagetitle": "Functions", "page_description": "Functions  Runhouse allows you to function code a cluster, but still interact with it as a native runnable Function object (see tutorial 01). When you do this, ", "author": "the Runhouse team \ud83c\udfc3\u200d\u2640\ufe0f\ud83c\udfe0", "github_user": "run-house", "github_repo": "runhouse", "github_version": "main", "doc_path": "docs/", "theme_search_bar_text": "Search the docs ...", "theme_show_toc_level": 1}