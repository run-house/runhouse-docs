{"parents": [{"link": "../", "title": "Runhouse Architecture"}], "prev": {"link": "../", "title": "Runhouse Architecture"}, "next": {"link": "../data/", "title": "Data"}, "title": "Compute", "meta": {}, "body": "<section id=\"compute\">\n<h1>Compute<a class=\"headerlink\" href=\"#compute\" title=\"Permalink to this heading\">\u00b6</a></h1>\n<p>The <a class=\"reference internal\" href=\"../../tutorials/api/compute/#function\"><span class=\"std std-ref\">Function</span></a>, <a class=\"reference internal\" href=\"../../tutorials/api/compute/#cluster\"><span class=\"std std-ref\">Cluster</span></a>, and <a class=\"reference internal\" href=\"../../api/package/#package\"><span class=\"std std-ref\">Package</span></a> APIs allow a seamless flow of code and execution across local and remote compute.\nThey blur the line between program execution and deployment, providing both a path of least resistence for running a\nsub-routine on specific hardware, while unceremoniously turning that sub-routine into a reusable service.</p>\n<p>They also provide convenient dependency isolation and management, provider-agnostic provisioning and termination,\nand rich debugging and accessibility interfaces built-in.</p>\n<section id=\"functions\">\n<h2>Functions<a class=\"headerlink\" href=\"#functions\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<p>Runhouse allows you to send function code to a cluster, but still interact with it as a native runnable <a class=\"reference internal\" href=\"../../tutorials/api/compute/#function\"><span class=\"std std-ref\">Function</span></a> object.\nWhen you do this, the following steps occur:</p>\n<ol class=\"arabic simple\">\n<li><p>We check if the cluster is up, and bring up the cluster if not (only possible for <span class=\"xref std std-ref\">OnDemandClusters</span>)</p></li>\n<li><p>We check that the cluster\u2019s RPC server has started to handle requests to do things like install packages, run modules, get previously executed results, etc. If it hasn\u2019t, we install Runhouse on the cluster and start the RPC server. The RPC server initializes Ray.</p></li>\n<li><p>We collect the dependencies from the <code class=\"code docutils literal notranslate\"><span class=\"pre\">reqs</span></code> parameter and install them on the cluster via <code class=\"code docutils literal notranslate\"><span class=\"pre\">cluster.install_packages()</span></code>. By default, we\u2019ll sync over the working git repo and install its <code class=\"code docutils literal notranslate\"><span class=\"pre\">requirements.txt</span></code> if it has one.</p></li>\n</ol>\n<p>When you run your function module, we send a RPC request to the cluster with the module name and function entrypoint to run.\nThe RPC server adds the module to its python path, imports the module, grabs the function entrypoint, runs it,\nand returns your results.</p>\n<p>We plan to support additional form factors for modules beyond \u201cremote Python function\u201d shortly, including HTTP endpoints, custom ASGIs, and more.</p>\n</section>\n<section id=\"clusters\">\n<h2>Clusters<a class=\"headerlink\" href=\"#clusters\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<p>A <a class=\"reference internal\" href=\"../../tutorials/api/compute/#cluster\"><span class=\"std std-ref\">Cluster</span></a> represents a set of machines which can be sent code or data, or a machine spec that could be spun up in the\nevent that we have some code or data to send to the machine.\nGenerally they are <a class=\"reference external\" href=\"https://docs.ray.io/en/latest/cluster/getting-started.html\">Ray clusters</a> under the hood.</p>\n<p>There are a few kinds of clusters today:</p>\n<section id=\"byo-cluster\">\n<h3>BYO Cluster<a class=\"headerlink\" href=\"#byo-cluster\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<p>This is a machine or group of machines specified by IP addresses and SSH credentials, which can be dispatched code\nor data through the Runhouse APIs. This is useful if you have an on-prem instance, or an account with <a class=\"reference external\" href=\"https://www.paperspace.com/\">Paperspace</a>,\n<a class=\"reference external\" href=\"https://www.coreweave.com/\">CoreWeave</a>, or another vertical provider, or simply want to spin up machines\nyourself through the cloud UI.</p>\n</section>\n<section id=\"on-demand-clusters\">\n<h3>On-Demand Clusters<a class=\"headerlink\" href=\"#on-demand-clusters\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<p>Runhouse can spin up and down boxes for you as needed using <a class=\"reference external\" href=\"https://github.com/skypilot-org/skypilot/\">SkyPilot</a>.\nWhen you define a SkyPilot \u201ccluster,\u201d\nyou\u2019re primarily defining the configuration for us to spin up the compute resources on-demand.\nWhen someone then calls a function or similar, we\u2019ll spin the box back up for you.</p>\n<p>SkyPilot also provides an excellent suite of CLI commands for basic instance management operations.\nSome important ones are:</p>\n<p><code class=\"code docutils literal notranslate\"><span class=\"pre\">sky</span> <span class=\"pre\">status</span> <span class=\"pre\">--refresh</span></code>: Get the status of the clusters you launched from this machine.\nThis will not pull the status for all the machines you\u2019ve launched from various environments.\nWe plan to add this feature soon.</p>\n<p><code class=\"code docutils literal notranslate\"><span class=\"pre\">sky</span> <span class=\"pre\">down</span> <span class=\"pre\">--all</span></code>: This will take down (terminate, without persisting the disk image) all clusters in the local\nSkyPilot context (the ones that show when you run <code class=\"code docutils literal notranslate\"><span class=\"pre\">sky</span> <span class=\"pre\">status</span> <span class=\"pre\">--refresh</span></code>). However, the best way to confirm that you\ndon\u2019t have any machines left running is always to check the cloud provider\u2019s UI.</p>\n<p><code class=\"code docutils literal notranslate\"><span class=\"pre\">sky</span> <span class=\"pre\">down</span> <span class=\"pre\">&lt;cluster_name&gt;</span></code>: This will take down a specific cluster.</p>\n<p><code class=\"code docutils literal notranslate\"><span class=\"pre\">ssh</span> <span class=\"pre\">&lt;cluster_name&gt;</span></code>: This will ssh into the head node of the cluster.\nSkyPilot cleverly adds the host information to your <code class=\"code docutils literal notranslate\"><span class=\"pre\">~/.ssh/config</span> <span class=\"pre\">file</span></code>, so ssh will just work.</p>\n<p><code class=\"code docutils literal notranslate\"><span class=\"pre\">sky</span> <span class=\"pre\">autostop</span> <span class=\"pre\">-i</span> <span class=\"pre\">&lt;minutes,</span> <span class=\"pre\">or</span> <span class=\"pre\">-1&gt;</span> <span class=\"pre\">&lt;cluster_name&gt;</span></code>: This will set the cluster to autostop after that many minutes of inactivity.\nYou can set it to -1 to disable autostop entirely. You can set your default autostop in <code class=\"code docutils literal notranslate\"><span class=\"pre\">~/.rh/config.yaml</span></code>.</p>\n</section>\n<section id=\"existing-clusters\">\n<h3>Existing Clusters<a class=\"headerlink\" href=\"#existing-clusters\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<p>\u201cExisting cluster\u201d can mean either a saved <span class=\"xref std std-ref\">OnDemandCluster</span> config, which will be brought back up if needed,\nor a BYO or OnDemandCluster that\u2019s already up. If you save the Cluster to the <a class=\"reference internal\" href=\"../accessibility/#resource-name-system-rns\"><span class=\"std std-ref\">Resource Name System (RNS)</span></a>,\nyou\u2019ll be able to dispatch to it from any environment. Multiple users or environments can send requests to a cluster\nwithout issue, and either the OS or Ray (depending on the call to the cluster) will handle the resource contention.</p>\n<p>You can load an existing cluster by name from local or Runhouse RNS simply by:</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">gpu</span> <span class=\"o\">=</span> <span class=\"n\">rh</span><span class=\"o\">.</span><span class=\"n\">cluster</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;~/my-local-a100&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">gpu</span> <span class=\"o\">=</span> <span class=\"n\">rh</span><span class=\"o\">.</span><span class=\"n\">cluster</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;@/my-a100-in-rh-rns&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">gpu</span> <span class=\"o\">=</span> <span class=\"n\">rh</span><span class=\"o\">.</span><span class=\"n\">cluster</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;^rh-v100&#39;</span><span class=\"p\">)</span>  <span class=\"c1\"># Loads a builtin cluster config</span>\n\n<span class=\"c1\"># or, if you just want to load the Cluster object without refreshing its status</span>\n<span class=\"n\">gpu</span> <span class=\"o\">=</span> <span class=\"n\">rh</span><span class=\"o\">.</span><span class=\"n\">cluster</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;^rh-v100&#39;</span><span class=\"p\">,</span> <span class=\"n\">dryrun</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n</section>\n</section>\n<section id=\"packages\">\n<h2>Packages<a class=\"headerlink\" href=\"#packages\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<p>A <a class=\"reference internal\" href=\"../../api/package/#package\"><span class=\"std std-ref\">Package</span></a> represents the way we share code between various systems (ex: s3, cluster, local),\nand back up the working directory to create a function that can be easily accessible and portable.\nThis allows Runhouse to load your code onto the cluster on the fly, as well as do basic registration and dispatch of\nthe <a class=\"reference internal\" href=\"../../tutorials/api/compute/#function\"><span class=\"std std-ref\">Function</span></a>.</p>\n<p>At a high level, we dump the list of packages into an RPC, and the packages are installed on the RPC server\non the cluster.</p>\n<p>We currently provide four general package install methods: local, requiements.txt, pip, and conda.</p>\n<section id=\"gitpackage\">\n<h3>GitPackage<a class=\"headerlink\" href=\"#gitpackage\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<p>Runhouse offers support for using a GitHub URL as GitPackage object, a subclass of <a class=\"reference internal\" href=\"../../api/package/#package\"><span class=\"std std-ref\">Package</span></a>.\nInstead of cloning down code from GitHub and copying it directly into your existing code base, you can provide a link\nto a specific <code class=\"code docutils literal notranslate\"><span class=\"pre\">git_url</span></code> (with support for a <code class=\"code docutils literal notranslate\"><span class=\"pre\">revision</span></code> version), and Runhouse handles all the installations\nfor you.</p>\n</section>\n</section>\n</section>\n\n    <script type=\"text/x-thebe-config\">\n    {\n        requestKernel: true,\n        binderOptions: {\n            repo: \"binder-examples/jupyter-stacks-datascience\",\n            ref: \"master\",\n        },\n        codeMirrorConfig: {\n            theme: \"abcdef\",\n            mode: \"python\"\n        },\n        kernelOptions: {\n            kernelName: \"python3\",\n            path: \"./architecture\"\n        },\n        predefinedOutput: true\n    }\n    </script>\n    <script>kernelName = 'python3'</script>", "metatags": "<meta name=\"generator\" content=\"Docutils 0.18.1: http://docutils.sourceforge.net/\" />\n", "rellinks": [["genindex", "General Index", "I", "index"], ["py-modindex", "Python Module Index", "", "modules"], ["architecture/data", "Data", "N", "next"], ["architecture", "Runhouse Architecture", "P", "previous"]], "sourcename": "architecture/compute.rst.txt", "toc": "<ul>\n<li><a class=\"reference internal\" href=\"#\">Compute</a><ul>\n<li><a class=\"reference internal\" href=\"#functions\">Functions</a></li>\n<li><a class=\"reference internal\" href=\"#clusters\">Clusters</a><ul>\n<li><a class=\"reference internal\" href=\"#byo-cluster\">BYO Cluster</a></li>\n<li><a class=\"reference internal\" href=\"#on-demand-clusters\">On-Demand Clusters</a></li>\n<li><a class=\"reference internal\" href=\"#existing-clusters\">Existing Clusters</a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#packages\">Packages</a><ul>\n<li><a class=\"reference internal\" href=\"#gitpackage\">GitPackage</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n", "display_toc": true, "page_source_suffix": ".rst", "current_page_name": "architecture/compute", "sidebars": ["sidebar-logo.html", "search-field.html", "sbt-sidebar-nav.html", "sbt-sidebar-footer.html"], "customsidebar": null, "favicon_url": null, "logo_url": null, "alabaster_version": "0.7.12", "pagetitle": "Compute", "page_description": "Compute  The Function, Cluster, and Package APIs allow a seamless flow of code and execution across local and remote compute. They blur the line between program", "author": "the Runhouse team \ud83c\udfc3\u200d\u2640\ufe0f\ud83c\udfe0", "github_user": "run-house", "github_repo": "runhouse", "github_version": "stable", "doc_path": "docs/", "theme_search_bar_text": "Search the docs ...", "theme_show_toc_level": 1}